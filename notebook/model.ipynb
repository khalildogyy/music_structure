{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7648, 132300) (7648, 258, 128) (7648, 258, 84) (7648, 258, 1025) (7648, 60, 12) (7648,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "origindata = np.load('../data/dataset/origindata.npy')\n",
    "meldata = np.load('../data/dataset/meldata.npy')\n",
    "cqtdata = np.load('../data/dataset/cqtdata.npy')\n",
    "stftdata = np.load('../data/dataset/stftdata.npy')\n",
    "genedata = np.load('../data/dataset/genedata.npy')\n",
    "label = np.load('../data/dataset/label.npy')\n",
    "print(origindata.shape, meldata.shape, cqtdata.shape, stftdata.shape, genedata.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "from sklearn import metrics\n",
    "import os, sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "class Dataloader():\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.pointer = 0\n",
    "        self.num_batch = 0\n",
    "\n",
    "    # Shuffle the data\n",
    "    def Shuffle(self, datalength):\n",
    "        shuffle_indices = np.random.permutation(np.arange(datalength))\n",
    "        return shuffle_indices\n",
    "\n",
    "    def SplitBatches(self, data):\n",
    "        datas = data[:self.num_batch * self.batch_size]\n",
    "        data_batches = np.split(datas, self.num_batch, 0)\n",
    "        return data_batches\n",
    "    \n",
    "    def load_data(self, x, y):\n",
    "        self.x = np.array(x, dtype=np.float32)\n",
    "        self.y = np.array(y, dtype=np.float32)\n",
    "\n",
    "        # Shuffle the data\n",
    "        shuffle_indices = self.Shuffle(self.x.shape[0])\n",
    "        self.x = self.x[shuffle_indices]\n",
    "        self.y = self.y[shuffle_indices]\n",
    "        # Split batches\n",
    "        self.num_batch = int(self.x.shape[0] / self.batch_size)\n",
    "        self.pointer = 0\n",
    "\n",
    "        self.x_batches = self.SplitBatches(self.x)\n",
    "        self.y_batches = self.SplitBatches(self.y)\n",
    "\n",
    "    def next_batch(self):\n",
    "        x_batch = self.x_batches[self.pointer]\n",
    "        y_batch = self.y_batches[self.pointer]\n",
    "\n",
    "        self.pointer = (self.pointer + 1) % self.num_batch\n",
    "        return x_batch, y_batch\n",
    "\n",
    "    def reset_pointer(self):\n",
    "        self.pointer = 0\n",
    "\n",
    "# data sample\n",
    "def sample(datax, datay):\n",
    "    data0 = datax[datay == 0]\n",
    "    data1 = datax[datay == 1]\n",
    "    index = np.random.randint(low=0, high = data0.shape[0], size = data1.shape[0] * 2)\n",
    "    data0 = data0[index]\n",
    "    datax = np.concatenate([data1, data0], axis=0)\n",
    "    datay = np.array([0] * datax.shape[0])\n",
    "    datay[0:data1.shape[0]] = 1\n",
    "    shuffle_indices = np.random.permutation(np.arange(datax.shape[0]))\n",
    "    datax, datay = datax[shuffle_indices], datay[shuffle_indices]\n",
    "    trainx, trainy = datax[:int(datax.shape[0] * 0.8)], datay[:int(datax.shape[0] * 0.8)]\n",
    "    testx, testy = datax[int(datax.shape[0] * 0.8):], datay[int(datax.shape[0] * 0.8):]\n",
    "    \n",
    "    return trainx, trainy, testx, testy\n",
    "\n",
    "# tslearn: euclidean, DTW, shaplets\n",
    "def TSlearn(datax, datay, method='euclidean'):\n",
    "    trainx, trainy, testx, testy = sample(datax, datay)\n",
    "    print(datax.shape, datay.shape, trainx.shape, testx.shape)\n",
    "    clf = KNeighborsTimeSeriesClassifier(n_neighbors=5, metric=method)\n",
    "    clf.fit(trainx, trainy)\n",
    "    y_pred = clf.predict(testx)\n",
    "\n",
    "    print ('Precision: {:04f}\\tRecall: {:04f}\\tF1: {:04f}'.format(\n",
    "        metrics.precision_score(testy, y_pred), \n",
    "        metrics.recall_score(testy, y_pred), \n",
    "        metrics.f1_score(testy, y_pred)))\n",
    "\n",
    "# rnn: LSTM, GRU\n",
    "def RNNlearn(datax, datay, method='LSTM', hiddens=[1024, 256]):\n",
    "    trainx, trainy, testx, testy = sample(datax, datay)\n",
    "    print(datax.shape, datay.shape, trainx.shape, testx.shape)\n",
    "    \n",
    "    # network\n",
    "    tf.reset_default_graph()\n",
    "    x = tf.placeholder(tf.float32, [None, datax.shape[1], datax.shape[2]], name='input_x')\n",
    "    y = tf.placeholder(tf.float32, [None, 2], name='input_y')\n",
    "    if method == 'LSTM':\n",
    "        rnn_fw_cell = tf.contrib.rnn.BasicLSTMCell(num_units=hiddens[0])\n",
    "        rnn_bw_cell = tf.contrib.rnn.BasicLSTMCell(num_units=hiddens[0])\n",
    "    elif method == 'GRU':\n",
    "        rnn_fw_cell = tf.contrib.rnn.GRUCell(num_units=hiddens[0])\n",
    "        rnn_bw_cell = tf.contrib.rnn.GRUCell(num_units=hiddens[0])\n",
    "        \n",
    "    outputs_fw, _ = tf.nn.dynamic_rnn(rnn_fw_cell, x[:, :int(datax.shape[1] * 2 / 3)], initial_state=None, dtype=tf.float32, time_major=True, scope='fw')\n",
    "    outputs_bw, _ = tf.nn.dynamic_rnn(rnn_bw_cell, x[:, int(datax.shape[1] * 2 / 3):][:, ::-1], initial_state=None, dtype=tf.float32, time_major=True, scope='bw')\n",
    "    \n",
    "    logits = tf.concat([outputs_fw[:, -1, :], outputs_bw[:, -1, :]], axis=-1)\n",
    "    net = tf.layers.dense(logits, hiddens[1], activation=tf.nn.relu)\n",
    "    out_logits = tf.layers.dense(net, 2)\n",
    "    out = tf.nn.softmax(out_logits, name='output')\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=y, logits=out_logits))\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        optim = tf.train.AdamOptimizer(learning_rate=0.01, beta1=0.7).minimize(loss)\n",
    "    \n",
    "    # train\n",
    "    trainy = np.eye(2, dtype=np.float32)[trainy]\n",
    "#     trainloader = Dataloader(100)\n",
    "#     trainloader.load_data(trainx, trainy)\n",
    "#     testloader = Dataloader(100)\n",
    "#     testloader.load_data(testx, testy)\n",
    "    \n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1.)\n",
    "    config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "    bestp = 0.0\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(100):\n",
    "            y_pred = []\n",
    "            losses = []\n",
    "            _, loss_ = sess.run([optim, loss], feed_dict={x: trainx, y: trainy})\n",
    "            out_ = sess.run(out, feed_dict={x: testx})\n",
    "            y_pred = np.argmax(out_, axis=1)\n",
    "#             trainloader.reset_pointer()\n",
    "#             for _ in range(trainloader.num_batch):\n",
    "#                 x_batch, y_batch = trainloader.next_batch()\n",
    "#                 _, loss_ = sess.run([optim, loss], feed_dict={x: x_batch, y: y_batch})\n",
    "#                 losses.append(loss_)\n",
    "                \n",
    "#             testloader.reset_pointer()\n",
    "#             for _ in range(testloader.num_batch):\n",
    "#                 x_batch, y_batch = testloader.next_batch()\n",
    "#                 out_ = sess.run(out, feed_dict={x: testx})\n",
    "#                 y_pred.append(out_)\n",
    "#             y_pred = np.argmax(y_pred)\n",
    "            precision = metrics.precision_score(testy, y_pred)\n",
    "            recall = metrics.recall_score(testy, y_pred)\n",
    "            f1 = metrics.f1_score(testy, y_pred)\n",
    "            if f1 > bestp:\n",
    "                saver.save(sess, './model/rnn')\n",
    "                bestp = f1\n",
    "            print ('Epochs {:d}\\tloss: {:04f}\\tPrecision: {:04f}\\tRecall: {:04f}\\tF1: {:04f}'.format(i, loss_,\n",
    "                precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7648, 1323) (7648,) (573, 1323) (144, 1323)\n",
      "Precision: 0.235294\tRecall: 0.102564\tF1: 0.142857\n"
     ]
    }
   ],
   "source": [
    "# euclidean\n",
    "TSlearn(origindata[:, range(0, origindata.shape[1], 100)], label, method='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7648, 60, 12) (7648,) (573, 60, 12) (144, 60, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwj/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/hwj/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 0\tloss: 0.705520\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 1\tloss: 0.681564\tPrecision: 0.323529\tRecall: 0.936170\tF1: 0.480874\n",
      "Epochs 2\tloss: 0.718564\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 3\tloss: 0.642847\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 4\tloss: 0.731084\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 5\tloss: 0.652996\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 6\tloss: 0.644079\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 7\tloss: 0.640774\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 8\tloss: 0.632796\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 9\tloss: 0.628488\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 10\tloss: 0.624584\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 11\tloss: 0.617431\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 12\tloss: 0.610248\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 13\tloss: 0.608820\tPrecision: 0.380952\tRecall: 0.170213\tF1: 0.235294\n",
      "Epochs 14\tloss: 0.604371\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 15\tloss: 0.719120\tPrecision: 0.346939\tRecall: 0.361702\tF1: 0.354167\n",
      "Epochs 16\tloss: 0.648350\tPrecision: 0.500000\tRecall: 0.021277\tF1: 0.040816\n",
      "Epochs 17\tloss: 0.637271\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 18\tloss: 0.618483\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 19\tloss: 0.629697\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 20\tloss: 0.614468\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 21\tloss: 0.613011\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 22\tloss: 0.598076\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 23\tloss: 0.590508\tPrecision: 0.303571\tRecall: 0.361702\tF1: 0.330097\n",
      "Epochs 24\tloss: 0.617777\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 25\tloss: 0.635307\tPrecision: 0.333333\tRecall: 0.106383\tF1: 0.161290\n",
      "Epochs 26\tloss: 0.595533\tPrecision: 0.500000\tRecall: 0.021277\tF1: 0.040816\n",
      "Epochs 27\tloss: 0.592171\tPrecision: 0.666667\tRecall: 0.042553\tF1: 0.080000\n",
      "Epochs 28\tloss: 0.578649\tPrecision: 1.000000\tRecall: 0.042553\tF1: 0.081633\n",
      "Epochs 29\tloss: 0.569692\tPrecision: 0.333333\tRecall: 0.042553\tF1: 0.075472\n",
      "Epochs 30\tloss: 0.557638\tPrecision: 0.222222\tRecall: 0.042553\tF1: 0.071429\n",
      "Epochs 31\tloss: 0.548528\tPrecision: 0.333333\tRecall: 0.085106\tF1: 0.135593\n",
      "Epochs 32\tloss: 0.535999\tPrecision: 0.500000\tRecall: 0.127660\tF1: 0.203390\n",
      "Epochs 33\tloss: 0.522900\tPrecision: 0.357143\tRecall: 0.106383\tF1: 0.163934\n",
      "Epochs 34\tloss: 0.508183\tPrecision: 0.277778\tRecall: 0.106383\tF1: 0.153846\n",
      "Epochs 35\tloss: 0.494972\tPrecision: 0.241379\tRecall: 0.148936\tF1: 0.184211\n",
      "Epochs 36\tloss: 0.524317\tPrecision: 0.310345\tRecall: 0.191489\tF1: 0.236842\n",
      "Epochs 37\tloss: 0.558817\tPrecision: 0.294118\tRecall: 0.212766\tF1: 0.246914\n",
      "Epochs 38\tloss: 0.563778\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 39\tloss: 0.638541\tPrecision: 0.298701\tRecall: 0.489362\tF1: 0.370968\n",
      "Epochs 40\tloss: 0.664444\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 41\tloss: 0.573286\tPrecision: 0.000000\tRecall: 0.000000\tF1: 0.000000\n",
      "Epochs 42\tloss: 0.566665\tPrecision: 0.250000\tRecall: 0.085106\tF1: 0.126984\n",
      "Epochs 43\tloss: 0.550760\tPrecision: 0.380952\tRecall: 0.170213\tF1: 0.235294\n",
      "Epochs 44\tloss: 0.537566\tPrecision: 0.400000\tRecall: 0.127660\tF1: 0.193548\n",
      "Epochs 45\tloss: 0.517024\tPrecision: 0.440000\tRecall: 0.234043\tF1: 0.305556\n",
      "Epochs 46\tloss: 0.507643\tPrecision: 0.304348\tRecall: 0.148936\tF1: 0.200000\n",
      "Epochs 47\tloss: 0.515789\tPrecision: 0.325581\tRecall: 0.297872\tF1: 0.311111\n",
      "Epochs 48\tloss: 0.537629\tPrecision: 0.500000\tRecall: 0.042553\tF1: 0.078431\n",
      "Epochs 49\tloss: 0.651434\tPrecision: 0.333333\tRecall: 0.361702\tF1: 0.346939\n",
      "Epochs 50\tloss: 0.571882\tPrecision: 0.321429\tRecall: 0.191489\tF1: 0.240000\n",
      "Epochs 51\tloss: 0.548328\tPrecision: 0.363636\tRecall: 0.085106\tF1: 0.137931\n",
      "Epochs 52\tloss: 0.537858\tPrecision: 0.363636\tRecall: 0.085106\tF1: 0.137931\n",
      "Epochs 53\tloss: 0.534647\tPrecision: 0.392857\tRecall: 0.234043\tF1: 0.293333\n",
      "Epochs 54\tloss: 0.554658\tPrecision: 0.500000\tRecall: 0.212766\tF1: 0.298507\n",
      "Epochs 55\tloss: 0.526080\tPrecision: 0.500000\tRecall: 0.191489\tF1: 0.276923\n",
      "Epochs 56\tloss: 0.521397\tPrecision: 0.476190\tRecall: 0.212766\tF1: 0.294118\n",
      "Epochs 57\tloss: 0.502280\tPrecision: 0.333333\tRecall: 0.212766\tF1: 0.259740\n",
      "Epochs 58\tloss: 0.476753\tPrecision: 0.384615\tRecall: 0.212766\tF1: 0.273973\n",
      "Epochs 59\tloss: 0.461864\tPrecision: 0.357143\tRecall: 0.319149\tF1: 0.337079\n",
      "Epochs 60\tloss: 0.449645\tPrecision: 0.413793\tRecall: 0.255319\tF1: 0.315789\n",
      "Epochs 61\tloss: 0.487494\tPrecision: 0.300000\tRecall: 0.255319\tF1: 0.275862\n",
      "Epochs 62\tloss: 0.506720\tPrecision: 0.333333\tRecall: 0.234043\tF1: 0.275000\n",
      "Epochs 63\tloss: 0.468517\tPrecision: 0.344828\tRecall: 0.212766\tF1: 0.263158\n",
      "Epochs 64\tloss: 0.446247\tPrecision: 0.306122\tRecall: 0.319149\tF1: 0.312500\n",
      "Epochs 65\tloss: 0.437850\tPrecision: 0.277778\tRecall: 0.106383\tF1: 0.153846\n",
      "Epochs 66\tloss: 0.475313\tPrecision: 0.328125\tRecall: 0.446809\tF1: 0.378378\n",
      "Epochs 67\tloss: 0.477191\tPrecision: 0.371429\tRecall: 0.276596\tF1: 0.317073\n",
      "Epochs 68\tloss: 0.413127\tPrecision: 0.454545\tRecall: 0.212766\tF1: 0.289855\n",
      "Epochs 69\tloss: 0.418826\tPrecision: 0.375000\tRecall: 0.255319\tF1: 0.303797\n",
      "Epochs 70\tloss: 0.408330\tPrecision: 0.250000\tRecall: 0.212766\tF1: 0.229885\n",
      "Epochs 71\tloss: 0.458226\tPrecision: 0.392857\tRecall: 0.234043\tF1: 0.293333\n",
      "Epochs 72\tloss: 0.431256\tPrecision: 0.333333\tRecall: 0.212766\tF1: 0.259740\n",
      "Epochs 73\tloss: 0.416106\tPrecision: 0.322581\tRecall: 0.212766\tF1: 0.256410\n",
      "Epochs 74\tloss: 0.385699\tPrecision: 0.423077\tRecall: 0.234043\tF1: 0.301370\n",
      "Epochs 75\tloss: 0.360005\tPrecision: 0.322581\tRecall: 0.212766\tF1: 0.256410\n",
      "Epochs 76\tloss: 0.334891\tPrecision: 0.289474\tRecall: 0.234043\tF1: 0.258824\n",
      "Epochs 77\tloss: 0.308847\tPrecision: 0.305556\tRecall: 0.234043\tF1: 0.265060\n",
      "Epochs 78\tloss: 0.283266\tPrecision: 0.307692\tRecall: 0.255319\tF1: 0.279070\n",
      "Epochs 79\tloss: 0.274507\tPrecision: 0.297297\tRecall: 0.234043\tF1: 0.261905\n",
      "Epochs 80\tloss: 0.299284\tPrecision: 0.300000\tRecall: 0.255319\tF1: 0.275862\n",
      "Epochs 81\tloss: 0.260318\tPrecision: 0.303030\tRecall: 0.212766\tF1: 0.250000\n",
      "Epochs 82\tloss: 0.229130\tPrecision: 0.236842\tRecall: 0.191489\tF1: 0.211765\n",
      "Epochs 83\tloss: 0.201622\tPrecision: 0.243243\tRecall: 0.191489\tF1: 0.214286\n",
      "Epochs 84\tloss: 0.177627\tPrecision: 0.229167\tRecall: 0.234043\tF1: 0.231579\n",
      "Epochs 85\tloss: 0.160639\tPrecision: 0.384615\tRecall: 0.212766\tF1: 0.273973\n",
      "Epochs 86\tloss: 0.196458\tPrecision: 0.304348\tRecall: 0.446809\tF1: 0.362069\n",
      "Epochs 87\tloss: 0.566427\tPrecision: 0.375000\tRecall: 0.127660\tF1: 0.190476\n",
      "Epochs 88\tloss: 0.420843\tPrecision: 0.285714\tRecall: 0.382979\tF1: 0.327273\n",
      "Epochs 89\tloss: 0.405510\tPrecision: 0.360000\tRecall: 0.191489\tF1: 0.250000\n",
      "Epochs 90\tloss: 0.354801\tPrecision: 0.333333\tRecall: 0.297872\tF1: 0.314607\n",
      "Epochs 91\tloss: 0.315605\tPrecision: 0.343750\tRecall: 0.234043\tF1: 0.278481\n",
      "Epochs 92\tloss: 0.269597\tPrecision: 0.311111\tRecall: 0.297872\tF1: 0.304348\n",
      "Epochs 93\tloss: 0.214049\tPrecision: 0.255814\tRecall: 0.234043\tF1: 0.244444\n",
      "Epochs 94\tloss: 0.182822\tPrecision: 0.292683\tRecall: 0.255319\tF1: 0.272727\n",
      "Epochs 95\tloss: 0.147180\tPrecision: 0.317073\tRecall: 0.276596\tF1: 0.295455\n",
      "Epochs 96\tloss: 0.119218\tPrecision: 0.333333\tRecall: 0.276596\tF1: 0.302326\n",
      "Epochs 97\tloss: 0.100138\tPrecision: 0.302326\tRecall: 0.276596\tF1: 0.288889\n",
      "Epochs 98\tloss: 0.079472\tPrecision: 0.333333\tRecall: 0.297872\tF1: 0.314607\n",
      "Epochs 99\tloss: 0.062302\tPrecision: 0.307692\tRecall: 0.255319\tF1: 0.279070\n"
     ]
    }
   ],
   "source": [
    "RNNlearn(genedata, label, method='GRU', hiddens=[128, 64])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
